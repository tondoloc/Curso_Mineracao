{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DM_09_04\n",
    "### Importar pacotes\n",
    "Vamos usar \"codecs\" para ler os arquivos de texto, \"re\" (que significa \"regular expressions\", ou expressões regulares) e \"collections\" para trabalhar com tokens e \"nltk\" (\"Natural Language Toolkit\") em diversas operações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "%matplotlib inline\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import copy\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos de algumas funções especializadas do NLTK que não estão incluídas por padrão. É possível baixar apenas a parte com as \"stopwords\", palavras irrelevantes, mas talvez seja mais fácil baixar tudo no NLTK. Observe que é um processo muito demorado; levou mais de 30 minutos em meu computador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixar o pacote \"stopwords\" do NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ler dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"JaneEyre.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jane_eyre = f.read()\n",
    "with codecs.open(\"WutheringHeights.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    wuthering_heights = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processar dados\n",
    "Verificar palavras irrelevantes em inglês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esw = stopwords.words('english')\n",
    "esw.append(\"would\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrar tokens (usando expressões regulares)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pattern = re.compile(\"^\\w+$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Criar função para contagem de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_counter(text):\n",
    "    tokens = WordPunctTokenizer().tokenize(PorterStemmer().stem(text))\n",
    "    tokens = list(map(lambda x: x.lower(), tokens))\n",
    "    tokens = [token for token in tokens if re.match(word_pattern, token) and token not in esw]\n",
    "    return collections.Counter(tokens), len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar função para cálculo da frequência absoluta e da frequência relativa das palavras mais comuns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(counter, size):\n",
    "    abs_freq = np.array([el[1] for el in counter])\n",
    "    rel_freq = abs_freq / size\n",
    "    index = [el[0] for el in counter]\n",
    "    df = pd.DataFrame(data=np.array([abs_freq, rel_freq]).T, index=index, columns=[\"Absolute frequency\", \"Relative frequency\"])\n",
    "    df.index.name = \"Most common words\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisar textos individuais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular as palavras mais comuns de _Jane Eyre_. Isso demora um pouco. Então, exibir as 10 mais comuns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute frequency</th>\n",
       "      <th>Relative frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most common words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>593.0</td>\n",
       "      <td>0.006789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>584.0</td>\n",
       "      <td>0.006686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr</th>\n",
       "      <td>543.0</td>\n",
       "      <td>0.006217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>504.0</td>\n",
       "      <td>0.005770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>397.0</td>\n",
       "      <td>0.004545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rochester</th>\n",
       "      <td>366.0</td>\n",
       "      <td>0.004190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>348.0</td>\n",
       "      <td>0.003984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jane</th>\n",
       "      <td>342.0</td>\n",
       "      <td>0.003916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>341.0</td>\n",
       "      <td>0.003904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sir</th>\n",
       "      <td>315.0</td>\n",
       "      <td>0.003607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Absolute frequency  Relative frequency\n",
       "Most common words                                        \n",
       "one                             593.0            0.006789\n",
       "said                            584.0            0.006686\n",
       "mr                              543.0            0.006217\n",
       "could                           504.0            0.005770\n",
       "like                            397.0            0.004545\n",
       "rochester                       366.0            0.004190\n",
       "well                            348.0            0.003984\n",
       "jane                            342.0            0.003916\n",
       "little                          341.0            0.003904\n",
       "sir                             315.0            0.003607"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "je_counter, je_size = get_text_counter(jane_eyre)\n",
    "make_df(je_counter.most_common(10), je_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvar as 1.000 palavras mais comuns de _Jane Eyre_ como CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "je_df = make_df(je_counter.most_common(1000), je_size)\n",
    "je_df.to_csv(\"JE_1000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular as palavras mais comuns de _Wuthering Heights_. Isso também demora um pouco. Exibir as 10 mais comuns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_counter, wh_size = get_text_counter(wuthering_heights)\n",
    "make_df(wh_counter.most_common(10), wh_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvar as 1.000 palavras mais comuns de _Wuthering Heights_ como CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_df = make_df(wh_counter.most_common(1000), wh_size)\n",
    "wh_df.to_csv(\"WH_1000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparar textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificar as palavras mais comuns nos dois documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counter = wh_counter + je_counter\n",
    "all_df = make_df(wh_counter.most_common(1000), 1)\n",
    "most_common_words = all_df.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar um quadro de dados com as diferenças de frequência das palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = []\n",
    "for word in most_common_words:\n",
    "    je_c = je_counter.get(word, 0) / je_size\n",
    "    wh_c = wh_counter.get(word, 0) / wh_size\n",
    "    d = abs(je_c - wh_c)\n",
    "    df_data.append([je_c, wh_c, d])\n",
    "dist_df = pd.DataFrame(data=df_data, index=most_common_words,\n",
    "                       columns=[\"Jane Eyre relative frequency\", \"Wuthering Heights relative frequency\",\n",
    "                                \"Relative frequency difference\"])\n",
    "dist_df.index.name = \"Most common words\"\n",
    "dist_df.sort_values(\"Relative frequency difference\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibir as palavras mais distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvar a lista completa com as palavras distintas como um CSV intitulado \"bronte.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df.to_csv(\"bronte.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
